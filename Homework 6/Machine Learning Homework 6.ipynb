{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:38:39.908654Z",
     "start_time": "2025-04-24T17:38:34.155685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# toc\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.api.models import Model\n",
    "from keras.api.layers import Input, Dense\n",
    "from keras.api.optimizers import Adam\n",
    "\n",
    "plt.style.use('../maroon_ipynb.mplstyle')"
   ],
   "id": "683f003c26d618df",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Problem 1\n",
    "A function $u(x, y)$ is defined on a unit square $x \\in [0, 1]$, $y \\in [0, 1]$, and obeys the following partial differential equation:\n",
    "\n",
    "$$\\nabla^2u(x, y) = e^{-x}\\left(x - a + y^3 + by\\right)$$\n",
    "\n",
    "Where $a$ and $b$ are constants. The function $u(x, y)$ is also subject to the following Dirichlet boundary conditions:\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "u(0, y) = y^3 \\\\\n",
    "u(1, y) = (1 + y^3)/e \\\\\n",
    "u(x, 0) = xe^{-x} \\\\\n",
    "u(x, 1) = e^{-x}(1 + x)\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "For particular values of $a$ and $b$ the analytic solution is:\n",
    "\n",
    "$$u(x, y) = e^{-x}(x + y^3)$$\n",
    "\n",
    "Construct a physics-informed neural network (PINN) to determine the unknown constants $a$ and $b$ which give this solution. Try to minimize the number of points away from the boundary which explicitly use the analytic solution. Plot how the prediction of $a$ and $b$ evolves with the number of training epochs.\n",
    "\n",
    "## Solution"
   ],
   "id": "d5b094caf7091b04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T17:40:53.619110Z",
     "start_time": "2025-04-24T17:40:51.921236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1) Set up the true solution and RHS for reference\n",
    "def u_exact(x_, y_):\n",
    "    return np.exp(-x_)*(x_ + y_**3)\n",
    "\n",
    "\n",
    "def f_rhs(x_, y_, a_, b_):\n",
    "    return np.exp(-x_)*(x_ - a_ + y_**3 + b_*y_)\n",
    "\n",
    "\n",
    "# 2) Generate collocation points\n",
    "N_b = 200  # boundary points\n",
    "N_f = 5000  # interior collocation (physics) points\n",
    "N_a = 10  # very few interior “analytic” points\n",
    "\n",
    "# boundary: x=0, x=1, y=0, y=1\n",
    "xb0 = np.zeros((N_b, 1))\n",
    "yb0 = np.random.rand(N_b, 1)\n",
    "xb1 = np.ones((N_b, 1))\n",
    "yb1 = np.random.rand(N_b, 1)\n",
    "yb2 = np.zeros((N_b, 1))\n",
    "xb2 = np.random.rand(N_b, 1)\n",
    "yb3 = np.ones((N_b, 1))\n",
    "xb3 = np.random.rand(N_b, 1)\n",
    "\n",
    "X_b = np.vstack([\n",
    "    np.hstack([xb0, yb0]),\n",
    "    np.hstack([xb1, yb1]),\n",
    "    np.hstack([xb2, yb2]),\n",
    "    np.hstack([xb3, yb3]),\n",
    "])\n",
    "u_b = np.vstack([\n",
    "    yb0**3,\n",
    "    (1 + yb1**3)/np.e,\n",
    "    xb2*np.exp(-xb2),\n",
    "    np.exp(-xb3)*(1 + xb3),\n",
    "])\n",
    "\n",
    "# interior physics points\n",
    "X_f = np.random.rand(N_f, 2)\n",
    "\n",
    "# a few interior analytic points\n",
    "X_a = np.random.rand(N_a, 2)\n",
    "u_a = u_exact(X_a[:, 0:1], X_a[:, 1:2])\n",
    "\n",
    "# 3) Build the neural net model u_nn(x,y)\n",
    "inp = Input(shape=(2,), name=\"xy\")\n",
    "x = Dense(50, activation=\"tanh\")(inp)\n",
    "x = Dense(50, activation=\"tanh\")(x)\n",
    "x = Dense(50, activation=\"tanh\")(x)\n",
    "out = Dense(1, activation=None)(x)\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "# 4) Trainable parameters a, b\n",
    "a = tf.Variable(1.0, dtype=tf.float32, trainable=True, name=\"a\")\n",
    "b = tf.Variable(1.0, dtype=tf.float32, trainable=True, name=\"b\")\n",
    "\n",
    "# 5) Optimizer\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "\n",
    "\n",
    "# 6) One training step\n",
    "@tf.function\n",
    "def train_step(X_b_, u_b_, X_f_, X_a_, u_a_):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # boundary loss\n",
    "        u_pred_b = model(X_b_, training=True)\n",
    "        loss_b = tf.reduce_mean((u_pred_b - u_b_)**2)\n",
    "\n",
    "        # physics loss: ∇² u - f = 0\n",
    "        x_f = X_f_[:, 0:1]\n",
    "        y_f = X_f_[:, 1:2]\n",
    "        with tf.GradientTape(persistent=True) as t2:\n",
    "            t2.watch([x_f, y_f])\n",
    "            u_f = model(tf.concat([x_f, y_f], axis=1), training=True)\n",
    "        u_x = t2.gradient(u_f, x_f)\n",
    "        u_xx = t2.gradient(u_x, x_f)\n",
    "        u_y = t2.gradient(u_f, y_f)\n",
    "        u_yy = t2.gradient(u_y, y_f)\n",
    "        lap = u_xx + u_yy\n",
    "        f_val = tf.exp(-x_f)*(x_f - a + y_f**3 + b*y_f)\n",
    "        loss_phys = tf.reduce_mean((lap - f_val)**2)\n",
    "\n",
    "        # analytic‐point loss (very few points)\n",
    "        u_pred_a = model(X_a_, training=True)\n",
    "        loss_a = tf.reduce_mean((u_pred_a - u_a_)**2)\n",
    "\n",
    "        loss_ = loss_b + loss_phys + 1e-3*loss_a\n",
    "\n",
    "    # compute gradients and apply\n",
    "    grads = tape.gradient(loss_, model.trainable_variables + [a, b])\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables + [a, b]))\n",
    "    return loss_, loss_b, loss_phys, loss_a\n",
    "\n",
    "\n",
    "# 7) Training loop\n",
    "epochs = 5000\n",
    "history = {\"a\": [], \"b\": [], \"loss\": []}\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss, lb, lp, la = train_step(\n",
    "        tf.convert_to_tensor(X_b, tf.float32),\n",
    "        tf.convert_to_tensor(u_b, tf.float32),\n",
    "        tf.convert_to_tensor(X_f, tf.float32),\n",
    "        tf.convert_to_tensor(X_a, tf.float32),\n",
    "        tf.convert_to_tensor(u_a, tf.float32),\n",
    "    )\n",
    "    history[\"a\"].append(a.numpy())\n",
    "    history[\"b\"].append(b.numpy())\n",
    "    history[\"loss\"].append(loss.numpy())\n",
    "\n",
    "    if epoch%500 == 0:\n",
    "        print(f\"Epoch {epoch:5d}: total_loss={loss:.3e}, a={a.numpy():.4f}, b={b.numpy():.4f}\")\n",
    "\n",
    "# 8) Plot the trajectories of a and b\n",
    "plt.plot(history[\"a\"], label=\"learned a\")\n",
    "plt.plot(history[\"b\"], label=\"learned b\")\n",
    "plt.hlines([2.0, 6.0], 0, epochs, linestyles=\"dashed\", label=[\"true a\", \"true b\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.title(\"Evolution of a and b during training\")\n",
    "plt.show()"
   ],
   "id": "7a855b1f52bf2582",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Gabe Morris\\AppData\\Local\\Temp\\ipykernel_6340\\4105196027.py\", line 79, in train_step  *\n        lap = u_xx + u_yy\n\n    TypeError: unsupported operand type(s) for +: 'NoneType' and 'NoneType'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 100\u001B[0m\n\u001B[0;32m     97\u001B[0m history \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m: [], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m: [], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m: []}\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m--> 100\u001B[0m     loss, lb, lp, la \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_b\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu_b\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    105\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    107\u001B[0m     history[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(a\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m    108\u001B[0m     history[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(b\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "File \u001B[1;32mC:\\machine_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\Users\\GABEMO~1\\AppData\\Local\\Temp\\__autograph_generated_filevcbr2j4i.py:22\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001B[1;34m(X_b_, u_b_, X_f_, X_a_, u_a_)\u001B[0m\n\u001B[0;32m     20\u001B[0m u_y \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(t2)\u001B[38;5;241m.\u001B[39mgradient, (ag__\u001B[38;5;241m.\u001B[39mld(u_f), ag__\u001B[38;5;241m.\u001B[39mld(y_f)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     21\u001B[0m u_yy \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(t2)\u001B[38;5;241m.\u001B[39mgradient, (ag__\u001B[38;5;241m.\u001B[39mld(u_y), ag__\u001B[38;5;241m.\u001B[39mld(y_f)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m---> 22\u001B[0m lap \u001B[38;5;241m=\u001B[39m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu_xx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu_yy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m f_val \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mexp, (\u001B[38;5;241m-\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(x_f),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope) \u001B[38;5;241m*\u001B[39m (ag__\u001B[38;5;241m.\u001B[39mld(x_f) \u001B[38;5;241m-\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(a) \u001B[38;5;241m+\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(y_f) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;241m+\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(b) \u001B[38;5;241m*\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(y_f))\n\u001B[0;32m     24\u001B[0m loss_phys \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mreduce_mean, ((ag__\u001B[38;5;241m.\u001B[39mld(lap) \u001B[38;5;241m-\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(f_val)) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m,), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n",
      "\u001B[1;31mTypeError\u001B[0m: in user code:\n\n    File \"C:\\Users\\Gabe Morris\\AppData\\Local\\Temp\\ipykernel_6340\\4105196027.py\", line 79, in train_step  *\n        lap = u_xx + u_yy\n\n    TypeError: unsupported operand type(s) for +: 'NoneType' and 'NoneType'\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
